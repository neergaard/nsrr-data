{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "# os.chdir(Path(os.path.abspath(\"\")).parent)\n",
                "os.chdir('/home/alexnz/Projects/detr')  # Change this path!\n",
                "from nsrr_data.datamodule import SleepEventDataModule"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Datamodule"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `SleepEventDataModule` class contains logic to iterate over event data by wrapping a `SleepEventDataset` class.\n",
                "The datamodule is also responsible for splitting the data into train/eval partitions using the `setup()` method, and the user can then get a PyTorch `DataLoader` for each partition from the respective `*_dataloader()` methods."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Instantiate class"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We pass a dictionary of parameters to the datamodule class in order to instantiate it.\n",
                "The only event-specific parameters of note are `events`, `default_event_window_duration`, `fs`, and `picks`, corresponding to the event code/event name, duration of default events, sampling frequency, and the specific channels to include.\n",
                "\n",
                "Any transformations of the input data, such as short-time Fourier or continuous wavelet transforms can be included by the `transform` parameter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from nsrr_data.datamodule.transforms import STFTTransform\n",
                "\n",
                "params = dict(\n",
                "    data_dir=\"data/processed/mros/lm\",\n",
                "    batch_size=16,\n",
                "    n_eval=2,\n",
                "    n_test=2,\n",
                "    num_workers=0,\n",
                "    seed=1337,\n",
                "    events={\"lm\": \"Leg movement\"},\n",
                "    window_duration=600,  # seconds\n",
                "    cache_data=True,\n",
                "    default_event_window_duration=[15],\n",
                "    event_buffer_duration=3,\n",
                "    factor_overlap=2,\n",
                "    fs=64,\n",
                "    matching_overlap=0.5,\n",
                "    n_jobs=-1,\n",
                "    n_records=10,\n",
                "    picks=[\"legl\", \"legr\"],\n",
                "    # transform=MultitaperTransform(128, 0.5, 35.0, tw=8.0, normalize=True),\n",
                "    transform=STFTTransform(\n",
                "        fs=64, segment_size=int(4.0 * 64), step_size=int(0.125 * 64), nfft=1024, normalize=True\n",
                "    ),\n",
                "    scaling=\"robust\",\n",
                ")\n",
                "dm = SleepEventDataModule(**params)\n",
                "print(dm)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Split dataset into train/eval partitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The datamodule will split the dataset into train/eval partitions by calling the setup() method.\n",
                "dm.setup('fit')\n",
                "train_dl, eval_dl = dm.train_dataloader(), dm.val_dataloader()\n",
                "\n",
                "# The dataloaders are generators, ie. we can iterate over them using a for-loop.\n",
                "for i, (data, events, records, *_) in enumerate(train_dl):\n",
                "    if i < 1:\n",
                "        print(f'Batch size: {data.shape[0]} | No. channels: {data.shape[1]} | No. timepoints {data.shape[-1]} | No. events: {sum([ev.shape[0] for ev in events])} | Data sample size: {list(data.shape[1:])} ')\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above line tells us that the batch contains 16 windows of shape (2, 513, 4801) with 2 channels and 4801 time points.\n",
                "The last number tells us that there are 513 frequency bins in the STFT (the `nfft` parameter is set to 1024, but since we have real data, the spectra will be symmetric, ie. the positive and negative frequency components are the same)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Access the underlying datasets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The underlying data windows can be accessed by indexing into the dataset. This will call the __getitem__() method and yield the signals, and associated events. \n",
                "The events' start times and durations are normalized to the window, ie. an event with elements (0.1, 0.025) in a 10 min window will start at 10 min x 60 s / min x 0.1 = 60 s , and will last 10 min x 60 s / min x 0.025 = 15 s."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ds = dm.train\n",
                "sample = train_ds[1]\n",
                "record = sample['record']\n",
                "data = sample['signal']\n",
                "events = sample['events']\n",
                "print(sample.keys())\n",
                "print(f'Record: {record} | No. channels: {data.shape[0]} | No. timepoints: {data.shape[-1]} | No. events: {len(events)} | Data shape: {data.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Similarly to described above, the print statement tells us that this sample contains 2 channels and 4801 timepoints.\n",
                "The remaining number describes the number of frequency components in the STFT."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Plotting signals"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can plot signals in the underlying dataset by using the `plot_signals()` method in the `SleepEventDataset`. Simply provide an index in the range `[0, len(dataset)]` and optionally a list of the applied channels:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ds.plot_signals(0, channel_names=['Leg L', \"Leg R\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Transforming data on the fly"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "By using the `transform` argument in the `SleepEventDataModule`, we can get spectrograms of the data as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ds.plot_spect(0, channel_idx=0, window_size=int(4.0 * train_ds.fs), step_size=int(0.125 * train_ds.fs), nfft=1024)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also combine the plots by using the `plot()` method:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib widget\n",
                "train_ds.plot(0, channel_names=['Leg L', 'Leg R'], channel_idx=0, window_size=int(4.0 * train_ds.fs), step_size=int(0.125 * train_ds.fs), nfft=1024)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.8 (conda)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "87f2bffab538fc57cb12ba16c255d8f2693dd38c7d4613c8bde43278bc7344c7"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
